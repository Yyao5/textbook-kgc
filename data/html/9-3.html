<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title></title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2299.4">
  <style type="text/css">
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.0px Times}
    span.s1 {font: 10.0px Helvetica}
    span.s2 {font: 7.5px Times; color: #000066}
    span.s3 {font: 10.0px Courier; color: #000066}
    span.s4 {color: #000066}
  </style>
</head>
<body>
<p class="p1">The term <span class="s1">privacy </span>refers to the right of an individual, a group of individuals, or an organization to keep</p>
<p class="p1">information of a personal or proprietary nature from being disclosed to others. Many nations view</p>
<p class="p1">privacy as a basic human right. The Universal Declaration of Human Rights, Article 12, states: “No</p>
<p class="p1">one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to</p>
<p class="p1">attacks upon his honor and reputation. Everyone has the right to the protection of the law against such</p>
<p class="p1">interference or attacks.”</p>
<p class="p1">The U.S. Constitution contains no express right to privacy; however, the Bill of Rights reflects the</p>
<p class="p1">concern of the framers for protecting specific aspects of privacy.<span class="s2">5 </span>In the United Kingdom privacy is</p>
<p class="p1">guaranteed by the Data Protection Act. The European Court of Human Rights has developed many</p>
<p class="p1">documents defining the right to privacy.</p>
<p class="p1">At the same time, the right to privacy is limited by laws. For example, taxation laws require individuals</p>
<p class="p1">to share information about personal income or earnings. Individual privacy may conflict with other basic</p>
<p class="p1">human rights, e.g., freedom of speech. Privacy laws differ from country to country; laws in one country</p>
<p class="p1">may require public disclosure of information considered private in other countries and cultures.</p>
<p class="p1">The digital age has confronted legislators with significant challenges related to privacy as new threats</p>
<p class="p1">have emerged. For example, personal information voluntarily shared, but stolen from sites granted access</p>
<p class="p1">to it or misused, can lead to <span class="s1">identity theft</span>.</p>
<p class="p1">Some countries have been more aggressive than others in addressing the new privacy concerns. For</p>
<p class="p1">example, the countries of the European Union (EU) have very strict laws governing handling of personal</p>
<p class="p1">data in the digital age. A sweeping new privacy right, the “right to be forgotten,” is codified as part of a</p>
<p class="p1">broad new proposed data protection regulation in the EU. This right addresses the following problem:</p>
<p class="p1">Today it is very hard to escape your past when every photo, status update, and tweet lives forever on</p>
<p class="p1">some Web site.</p>
<p class="p1">Our discussion targets primarily public clouds where privacy has an entirely new dimension because</p>
<p class="p1">the data, often in an unencrypted form, resides on servers owned by a CSP. Services based on individual</p>
<p class="p1">preferences, the location of individuals, membership in social networks, or other personal information present a special risk. The owner of the data cannot rely exclusively on the CSP to guarantee the privacy</p>
<p class="p1">of the data.</p>
<p class="p1">Privacy concerns are different for the three cloud delivery models and also depend on the actual</p>
<p class="p1">context. For example, consider Gmail, a widely used <span class="s1">SaaS </span>delivery model. Gmail privacy policy reads</p>
<p class="p1">(see <span class="s3">www.google.com/policies/privacy/</span>, accessed on October 6, 2012): “We collect information</p>
<p class="p1">in two ways: information you give us <span class="s1">. . . </span>like your name, email address, telephone number or</p>
<p class="p1">credit card; information we get from your use of our services such as: <span class="s1">. . . </span>device information, <span class="s1">. . . </span>log</p>
<p class="p1">information, <span class="s1">. . . </span>location information, <span class="s1">. . . </span>unique application numbers, <span class="s1">. . . </span>local storage, <span class="s1">. . . </span>cookies</p>
<p class="p1">and anonymous identifiers <span class="s1">. . . </span>We will share personal information with companies, organizations or</p>
<p class="p1">individuals outside of Google if we have a good-faith belief that access, use, preservation or disclosure</p>
<p class="p1">of the information is reasonably necessary to: meet any applicable law, regulation, legal process or</p>
<p class="p1">enforceable governmental request <span class="s1">. . . </span>protect against harm to the rights, property or safety of Google,</p>
<p class="p1">our users or the public as required or permitted by law. We may share aggregated, nonpersonally identifiable</p>
<p class="p1">information publicly and with our partners like publishers, advertisers or connected sites. For</p>
<p class="p1">example, we may share information publicly to show trends about the general use of our services.”</p>
<p class="p1">The main aspects of privacy are: the lack of user control, potential unauthorized secondary use, data</p>
<p class="p1">proliferation, and dynamic provisioning [<span class="s4">290</span>]. The lack of user control refers to the fact that user-centric</p>
<p class="p1">data control is incompatible with cloud usage. Once data is stored on the CSP’s servers, the user loses</p>
<p class="p1">control of the exact location, and in some instances the user could lose access to the data. For example,</p>
<p class="p1">in case of the Gmail service, the account owner has no control over where the data is stored or how long</p>
<p class="p1">old emails are stored in some backups of the servers.</p>
<p class="p1">A CSP may obtain revenues from unauthorized secondary usage of the information, e.g., for targeted</p>
<p class="p1">advertising. There are no technological means to prevent this use. Dynamic provisioning refers to threats</p>
<p class="p1">due to outsourcing. A range of issues is very fuzzy; for example, how to identify the subcontractors of</p>
<p class="p1">a CSP, what rights to the data they have, and what rights to data are transferable in case of bankruptcy</p>
<p class="p1">or merger.</p>
<p class="p1">There is a need for legislation addressing the multiple aspects of privacy in the digital age. A document</p>
<p class="p1">elaborated by the Federal Trade Commission for the U.S. Congress states [<span class="s4">122</span>]: “Consumer-oriented</p>
<p class="p1">commercial Web sites that collect personal identifying information from or about consumers online</p>
<p class="p1">would be required to comply with the four widely accepted fair information practices:</p>
<p class="p1"><span class="s1">1. Notice. </span>Web sites would be required to provide consumers clear and conspicuous notice of their</p>
<p class="p1">information practices, including what information they collect, how they collect it (e.g., directly or</p>
<p class="p1">through nonobvious means such as cookies), how they use it, how they provide Choice, Access, and</p>
<p class="p1">Security to consumers, whether they disclose the information collected to other entities, and whether</p>
<p class="p1">other entities are collecting information through the site.</p>
<p class="p1"><span class="s1">2. Choice.</span>Web sites would be required to offer consumers choices as to how their personal identifying</p>
<p class="p1">information is used beyond the use for which the information was provided (e.g., to consummate a</p>
<p class="p1">transaction). Such choice would encompass both internal secondary uses (such as marketing back</p>
<p class="p1">to consumers) and external secondary uses (such as disclosing data to other entities).</p>
<p class="p1"><span class="s1">3. Access.</span>Web sites would be required to offer consumers reasonable access to the information aWeb</p>
<p class="p1">site has collected about them, including a reasonable opportunity to review information and to correct</p>
<p class="p1">inaccuracies or delete information.</p>
<p class="p1"><span class="s1">4. Security. </span>Web sites would be required to take reasonable steps to protect the security of the information</p>
<p class="p1">they collect from consumers. The Commission recognizes that the implementation of these practices</p>
<p class="p1">may vary with the nature of the information collected and the uses to which it is put, as well as with</p>
<p class="p1">technological developments. For this reason, the Commission recommends that any legislation be</p>
<p class="p1">phrased in general terms and be technologically neutral. Thus, the definitions of fair information</p>
<p class="p1">practices set forth in the statute should be broad enough to provide flexibility to the implementing</p>
<p class="p1">agency in promulgating its rules or regulations.”</p>
<p class="p1">There is a need for tools capable of identifying privacy issues in information systems, the so-called</p>
<p class="p1"><span class="s1">Privacy Impact Assesment (PIA)</span>. As of mid-2012 there were no international standards for such a</p>
<p class="p1">process, though different countries and organizations require PIA reports. An example of an analysis</p>
<p class="p1">is to assess the legal implications of the U.K.-U.S. Safe Harbor process to allow U.S. companies to</p>
<p class="p1">comply with the European Directive 95/46/EC<span class="s2">6 </span>on the protection of personal data.</p>
<p class="p1">Such an assessment forces a proactive attitude toward privacy. An ab-initio approach to embedding</p>
<p class="p1">privacy rules in new systems is preferable to painful changes that could affect the functionality of</p>
<p class="p1">existing systems.</p>
<p class="p1">A PIA tool that could be deployed as aWeb-based service is proposed in [<span class="s4">345</span>]. The inputs to the tool</p>
<p class="p1">includes project information, an outline of project documents, privacy risks, and stakeholders. The tool</p>
<p class="p1">will produce a PIA report consisting of a summary of findings, a risk summary, security, transparency,</p>
<p class="p1">and cross-border data flows.</p>
<p class="p1">The centerpiece of the PIA tool is a knowledge base (KB) created and maintained by domain experts.</p>
<p class="p1">The users of the <span class="s1">SaaS </span>service providing access to the PIA tool must fill in a questionnaire. The system</p>
<p class="p1">uses templates to generate additional questions necessary and to fill in the PIA report. An expert system</p>
<p class="p1">infers which rules are satisfied by the facts in the database and provided by the users and executes the</p>
<p class="p1">rule with the highest priority.</p>
</body>
</html>
